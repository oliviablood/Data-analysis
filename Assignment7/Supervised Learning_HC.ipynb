{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 7: Supervised learning\n",
    "###  Jiayu Chen (jic117)  Huan Chen (huc48)  Chang Tian (cht97)\n",
    "For the following two data sets, originating from the Irvine Machine Learning Repository (http://archive.ics.uci.edu/ml/):\n",
    "\n",
    "1) Iris (http://archive.ics.uci.edu/ml/datasets/Iris)\n",
    "\n",
    "2) Congressional Voting Records (http://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records)\n",
    "\n",
    "a) Build classification models based on each of these algorithms:\n",
    "\n",
    "Logistic Regression or SVM\n",
    "Random Forest or Boosting (i.e. Adaboost)\n",
    "CART (i.e. Decision Tree)\n",
    "The models should help in classification of types of iris flowers (1) and the parties of congressmen (2) based on flower properties and voting record, respectively. Clean up and discretize the data, if needed (if you need domain knowledge, you can read more about the data sets in the descriptions placed at UCI Repository). Make sure to try different learning algorithms and their parameters.\n",
    "\n",
    "Once you have learned models, check and report their classification accuracy (by means of a cross-validation method). Try to improve the accuracy by using\n",
    "\n",
    "b) feature selection,\n",
    "\n",
    "c) feature expansion (e.g. pairwise interactions, kernel trick), and,\n",
    "\n",
    "d) combine both together.\n",
    "\n",
    "Report the best classification accuracy that you have been able to achieve for each of the two data sets along with the methods that gave you the best accuracy. Make sure to summarize your observations and conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel,SelectKBest, chi2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "iris_dataset=load_iris()\n",
    "print(iris_dataset.keys())\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data= np.c_[iris_dataset['data'],iris_dataset['target']], columns=iris_dataset['feature_names']+['target'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:, 0:4]\n",
    "y=df.iloc[:, 4]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuningPara_crossValid(model, param_grid):\n",
    "    kfold = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kfold)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    accuracy = grid_search.score(x_test, y_test)\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    print('Best cross-validation score:', grid_search.best_score_)\n",
    "    print('The accuracy score is:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression: parameter tuning & cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'penalty': 'l2'}\n",
      "Best cross-validation score: 0.9732142857142857\n",
      "The accuracy score is: 0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "# tunning parameters\n",
    "param_grid = {'penalty':['l1', 'l2'], \n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "tuningPara_crossValid(LogisticRegression(), param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest: parameter tuning & cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 4, 'n_estimators': 3}\n",
      "Best cross-validation score: 0.9642857142857143\n",
      "The accuracy score is: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# tunning parameters \n",
    "# max_feature for classification problem is sqrt(n_features)\n",
    "param_grid = {'n_estimators': [2, 3, 4, 5],\n",
    "              'max_depth':[2, 3, 4, 5]}\n",
    "\n",
    "tuningPara_crossValid(RandomForestClassifier(max_features=2, n_jobs=-1), param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: parameter tuning & cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 3}\n",
      "Best cross-validation score: 0.9732142857142857\n",
      "The accuracy score is: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth':[1, 2, 3, 4, 5]}\n",
    "\n",
    "tuningPara_crossValid(DecisionTreeClassifier(), param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "select three features: spal length, petal length, petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.109369</td>\n",
       "      <td>0.871754</td>\n",
       "      <td>0.817954</td>\n",
       "      <td>0.782561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal length (cm)</th>\n",
       "      <td>0.871754</td>\n",
       "      <td>-0.420516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962757</td>\n",
       "      <td>0.949043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal width (cm)</th>\n",
       "      <td>0.817954</td>\n",
       "      <td>-0.356544</td>\n",
       "      <td>0.962757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0.782561</td>\n",
       "      <td>-0.419446</td>\n",
       "      <td>0.949043</td>\n",
       "      <td>0.956464</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "sepal length (cm)           1.000000         -0.109369           0.871754   \n",
       "petal length (cm)           0.871754         -0.420516           1.000000   \n",
       "petal width (cm)            0.817954         -0.356544           0.962757   \n",
       "target                      0.782561         -0.419446           0.949043   \n",
       "\n",
       "                   petal width (cm)    target  \n",
       "sepal length (cm)          0.817954  0.782561  \n",
       "petal length (cm)          0.962757  0.949043  \n",
       "petal width (cm)           1.000000  0.956464  \n",
       "target                     0.956464  1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113a96a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat = df.corr()\n",
    "sns.heatmap(corrmat, vmax=0.9, square=True)\n",
    "corrmat[corrmat['target']>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "x_new = SelectKBest(chi2, k=3).fit_transform(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x_new, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuningPara_crossValid1(model, param_grid):\n",
    "    kfold = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kfold)\n",
    "    grid_search.fit(x1_train, y1_train)\n",
    "    accuracy = grid_search.score(x1_test, y1_test)\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    print('Best cross-validation score:', grid_search.best_score_)\n",
    "    print('The accuracy score is:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'penalty': 'l1'}\n",
      "Best cross-validation score: 0.9821428571428571\n",
      "The accuracy score is: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression: parameter tuning & cross validation\n",
    "# tunning parameters\n",
    "param_grid = {'penalty':['l1', 'l2'], \n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "tuningPara_crossValid1(LogisticRegression(), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 2, 'n_estimators': 4}\n",
      "Best cross-validation score: 0.9642857142857143\n",
      "The accuracy score is: 0.8947368421052632\n"
     ]
    }
   ],
   "source": [
    "# Random Forest: parameter tuning & cross validation\n",
    "# tunning parameters \n",
    "# max_feature for classification problem is sqrt(n_features)\n",
    "param_grid = {'n_estimators': [2, 3, 4, 5],\n",
    "              'max_depth':[2, 3, 4, 5]}\n",
    "\n",
    "tuningPara_crossValid1(RandomForestClassifier(max_features=2, n_jobs=-1), param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 3}\n",
      "Best cross-validation score: 0.9732142857142857\n",
      "The accuracy score is: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree: parameter tuning & cross validation\n",
    "param_grid = {'max_depth':[1, 2, 3, 4, 5]}\n",
    "tuningPara_crossValid1(DecisionTreeClassifier(), param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:, 0:4]\n",
    "y=df.iloc[:, 4]\n",
    "\n",
    "# pairwise interactions\n",
    "poly = PolynomialFeatures(interaction_only=True,include_bias = False)\n",
    "x=poly.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Logistic Regression \n",
      "\n",
      "Best parameters: {'C': 10, 'penalty': 'l1'}\n",
      "Best cross-validation score: 0.9732142857142857\n",
      "The accuracy score is: 0.9736842105263158\n",
      "None\n",
      "\n",
      " Random Forest \n",
      "\n",
      "Best parameters: {'max_depth': 2, 'n_estimators': 5}\n",
      "Best cross-validation score: 0.9642857142857143\n",
      "The accuracy score is: 0.9736842105263158\n",
      "None\n",
      "\n",
      " Decision Tree \n",
      "\n",
      "Best parameters: {'max_depth': 4}\n",
      "Best cross-validation score: 0.9732142857142857\n",
      "The accuracy score is: 0.9736842105263158\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def tuningPara_crossValid1(model, param_grid):\n",
    "    kfold = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kfold)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    accuracy = grid_search.score(x_test, y_test)\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    print('Best cross-validation score:', grid_search.best_score_)\n",
    "    print('The accuracy score is:', accuracy)\n",
    "\n",
    "# Logistic Regression: parameter tuning & cross validation\n",
    "# tunning parameters\n",
    "param_grid = {'penalty':['l1', 'l2'], \n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "print('\\n Logistic Regression \\n')\n",
    "print(tuningPara_crossValid1(LogisticRegression(), param_grid))\n",
    "\n",
    "# Random Forest: parameter tuning & cross validation\n",
    "# tunning parameters \n",
    "# max_feature for classification problem is sqrt(n_features)\n",
    "param_grid = {'n_estimators': [2, 3, 4, 5],\n",
    "              'max_depth':[2, 3, 4, 5]}\n",
    "print('\\n Random Forest \\n')\n",
    "print(tuningPara_crossValid1(RandomForestClassifier(max_features=2, n_jobs=-1), param_grid))\n",
    "\n",
    "# Decision Tree: parameter tuning & cross validation\n",
    "param_grid = {'max_depth':[1, 2, 3, 4, 5]}\n",
    "\n",
    "print('\\n Decision Tree \\n')\n",
    "print(tuningPara_crossValid1(DecisionTreeClassifier(), param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## combine feature selection (excluding petal-width) and feature expansion together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:, range(0,4)]\n",
    "y=df.iloc[:, 4]\n",
    "# feature selection\n",
    "x = SelectKBest(chi2, k=3).fit_transform(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1 ,  1.4 ,  0.2 ,  7.14,  1.02,  0.28],\n",
       "       [ 4.9 ,  1.4 ,  0.2 ,  6.86,  0.98,  0.28],\n",
       "       [ 4.7 ,  1.3 ,  0.2 ,  6.11,  0.94,  0.26],\n",
       "       [ 4.6 ,  1.5 ,  0.2 ,  6.9 ,  0.92,  0.3 ],\n",
       "       [ 5.  ,  1.4 ,  0.2 ,  7.  ,  1.  ,  0.28],\n",
       "       [ 5.4 ,  1.7 ,  0.4 ,  9.18,  2.16,  0.68],\n",
       "       [ 4.6 ,  1.4 ,  0.3 ,  6.44,  1.38,  0.42],\n",
       "       [ 5.  ,  1.5 ,  0.2 ,  7.5 ,  1.  ,  0.3 ],\n",
       "       [ 4.4 ,  1.4 ,  0.2 ,  6.16,  0.88,  0.28],\n",
       "       [ 4.9 ,  1.5 ,  0.1 ,  7.35,  0.49,  0.15],\n",
       "       [ 5.4 ,  1.5 ,  0.2 ,  8.1 ,  1.08,  0.3 ],\n",
       "       [ 4.8 ,  1.6 ,  0.2 ,  7.68,  0.96,  0.32],\n",
       "       [ 4.8 ,  1.4 ,  0.1 ,  6.72,  0.48,  0.14],\n",
       "       [ 4.3 ,  1.1 ,  0.1 ,  4.73,  0.43,  0.11],\n",
       "       [ 5.8 ,  1.2 ,  0.2 ,  6.96,  1.16,  0.24],\n",
       "       [ 5.7 ,  1.5 ,  0.4 ,  8.55,  2.28,  0.6 ],\n",
       "       [ 5.4 ,  1.3 ,  0.4 ,  7.02,  2.16,  0.52],\n",
       "       [ 5.1 ,  1.4 ,  0.3 ,  7.14,  1.53,  0.42],\n",
       "       [ 5.7 ,  1.7 ,  0.3 ,  9.69,  1.71,  0.51],\n",
       "       [ 5.1 ,  1.5 ,  0.3 ,  7.65,  1.53,  0.45],\n",
       "       [ 5.4 ,  1.7 ,  0.2 ,  9.18,  1.08,  0.34],\n",
       "       [ 5.1 ,  1.5 ,  0.4 ,  7.65,  2.04,  0.6 ],\n",
       "       [ 4.6 ,  1.  ,  0.2 ,  4.6 ,  0.92,  0.2 ],\n",
       "       [ 5.1 ,  1.7 ,  0.5 ,  8.67,  2.55,  0.85],\n",
       "       [ 4.8 ,  1.9 ,  0.2 ,  9.12,  0.96,  0.38],\n",
       "       [ 5.  ,  1.6 ,  0.2 ,  8.  ,  1.  ,  0.32],\n",
       "       [ 5.  ,  1.6 ,  0.4 ,  8.  ,  2.  ,  0.64],\n",
       "       [ 5.2 ,  1.5 ,  0.2 ,  7.8 ,  1.04,  0.3 ],\n",
       "       [ 5.2 ,  1.4 ,  0.2 ,  7.28,  1.04,  0.28],\n",
       "       [ 4.7 ,  1.6 ,  0.2 ,  7.52,  0.94,  0.32],\n",
       "       [ 4.8 ,  1.6 ,  0.2 ,  7.68,  0.96,  0.32],\n",
       "       [ 5.4 ,  1.5 ,  0.4 ,  8.1 ,  2.16,  0.6 ],\n",
       "       [ 5.2 ,  1.5 ,  0.1 ,  7.8 ,  0.52,  0.15],\n",
       "       [ 5.5 ,  1.4 ,  0.2 ,  7.7 ,  1.1 ,  0.28],\n",
       "       [ 4.9 ,  1.5 ,  0.1 ,  7.35,  0.49,  0.15],\n",
       "       [ 5.  ,  1.2 ,  0.2 ,  6.  ,  1.  ,  0.24],\n",
       "       [ 5.5 ,  1.3 ,  0.2 ,  7.15,  1.1 ,  0.26],\n",
       "       [ 4.9 ,  1.5 ,  0.1 ,  7.35,  0.49,  0.15],\n",
       "       [ 4.4 ,  1.3 ,  0.2 ,  5.72,  0.88,  0.26],\n",
       "       [ 5.1 ,  1.5 ,  0.2 ,  7.65,  1.02,  0.3 ],\n",
       "       [ 5.  ,  1.3 ,  0.3 ,  6.5 ,  1.5 ,  0.39],\n",
       "       [ 4.5 ,  1.3 ,  0.3 ,  5.85,  1.35,  0.39],\n",
       "       [ 4.4 ,  1.3 ,  0.2 ,  5.72,  0.88,  0.26],\n",
       "       [ 5.  ,  1.6 ,  0.6 ,  8.  ,  3.  ,  0.96],\n",
       "       [ 5.1 ,  1.9 ,  0.4 ,  9.69,  2.04,  0.76],\n",
       "       [ 4.8 ,  1.4 ,  0.3 ,  6.72,  1.44,  0.42],\n",
       "       [ 5.1 ,  1.6 ,  0.2 ,  8.16,  1.02,  0.32],\n",
       "       [ 4.6 ,  1.4 ,  0.2 ,  6.44,  0.92,  0.28],\n",
       "       [ 5.3 ,  1.5 ,  0.2 ,  7.95,  1.06,  0.3 ],\n",
       "       [ 5.  ,  1.4 ,  0.2 ,  7.  ,  1.  ,  0.28],\n",
       "       [ 7.  ,  4.7 ,  1.4 , 32.9 ,  9.8 ,  6.58],\n",
       "       [ 6.4 ,  4.5 ,  1.5 , 28.8 ,  9.6 ,  6.75],\n",
       "       [ 6.9 ,  4.9 ,  1.5 , 33.81, 10.35,  7.35],\n",
       "       [ 5.5 ,  4.  ,  1.3 , 22.  ,  7.15,  5.2 ],\n",
       "       [ 6.5 ,  4.6 ,  1.5 , 29.9 ,  9.75,  6.9 ],\n",
       "       [ 5.7 ,  4.5 ,  1.3 , 25.65,  7.41,  5.85],\n",
       "       [ 6.3 ,  4.7 ,  1.6 , 29.61, 10.08,  7.52],\n",
       "       [ 4.9 ,  3.3 ,  1.  , 16.17,  4.9 ,  3.3 ],\n",
       "       [ 6.6 ,  4.6 ,  1.3 , 30.36,  8.58,  5.98],\n",
       "       [ 5.2 ,  3.9 ,  1.4 , 20.28,  7.28,  5.46],\n",
       "       [ 5.  ,  3.5 ,  1.  , 17.5 ,  5.  ,  3.5 ],\n",
       "       [ 5.9 ,  4.2 ,  1.5 , 24.78,  8.85,  6.3 ],\n",
       "       [ 6.  ,  4.  ,  1.  , 24.  ,  6.  ,  4.  ],\n",
       "       [ 6.1 ,  4.7 ,  1.4 , 28.67,  8.54,  6.58],\n",
       "       [ 5.6 ,  3.6 ,  1.3 , 20.16,  7.28,  4.68],\n",
       "       [ 6.7 ,  4.4 ,  1.4 , 29.48,  9.38,  6.16],\n",
       "       [ 5.6 ,  4.5 ,  1.5 , 25.2 ,  8.4 ,  6.75],\n",
       "       [ 5.8 ,  4.1 ,  1.  , 23.78,  5.8 ,  4.1 ],\n",
       "       [ 6.2 ,  4.5 ,  1.5 , 27.9 ,  9.3 ,  6.75],\n",
       "       [ 5.6 ,  3.9 ,  1.1 , 21.84,  6.16,  4.29],\n",
       "       [ 5.9 ,  4.8 ,  1.8 , 28.32, 10.62,  8.64],\n",
       "       [ 6.1 ,  4.  ,  1.3 , 24.4 ,  7.93,  5.2 ],\n",
       "       [ 6.3 ,  4.9 ,  1.5 , 30.87,  9.45,  7.35],\n",
       "       [ 6.1 ,  4.7 ,  1.2 , 28.67,  7.32,  5.64],\n",
       "       [ 6.4 ,  4.3 ,  1.3 , 27.52,  8.32,  5.59],\n",
       "       [ 6.6 ,  4.4 ,  1.4 , 29.04,  9.24,  6.16],\n",
       "       [ 6.8 ,  4.8 ,  1.4 , 32.64,  9.52,  6.72],\n",
       "       [ 6.7 ,  5.  ,  1.7 , 33.5 , 11.39,  8.5 ],\n",
       "       [ 6.  ,  4.5 ,  1.5 , 27.  ,  9.  ,  6.75],\n",
       "       [ 5.7 ,  3.5 ,  1.  , 19.95,  5.7 ,  3.5 ],\n",
       "       [ 5.5 ,  3.8 ,  1.1 , 20.9 ,  6.05,  4.18],\n",
       "       [ 5.5 ,  3.7 ,  1.  , 20.35,  5.5 ,  3.7 ],\n",
       "       [ 5.8 ,  3.9 ,  1.2 , 22.62,  6.96,  4.68],\n",
       "       [ 6.  ,  5.1 ,  1.6 , 30.6 ,  9.6 ,  8.16],\n",
       "       [ 5.4 ,  4.5 ,  1.5 , 24.3 ,  8.1 ,  6.75],\n",
       "       [ 6.  ,  4.5 ,  1.6 , 27.  ,  9.6 ,  7.2 ],\n",
       "       [ 6.7 ,  4.7 ,  1.5 , 31.49, 10.05,  7.05],\n",
       "       [ 6.3 ,  4.4 ,  1.3 , 27.72,  8.19,  5.72],\n",
       "       [ 5.6 ,  4.1 ,  1.3 , 22.96,  7.28,  5.33],\n",
       "       [ 5.5 ,  4.  ,  1.3 , 22.  ,  7.15,  5.2 ],\n",
       "       [ 5.5 ,  4.4 ,  1.2 , 24.2 ,  6.6 ,  5.28],\n",
       "       [ 6.1 ,  4.6 ,  1.4 , 28.06,  8.54,  6.44],\n",
       "       [ 5.8 ,  4.  ,  1.2 , 23.2 ,  6.96,  4.8 ],\n",
       "       [ 5.  ,  3.3 ,  1.  , 16.5 ,  5.  ,  3.3 ],\n",
       "       [ 5.6 ,  4.2 ,  1.3 , 23.52,  7.28,  5.46],\n",
       "       [ 5.7 ,  4.2 ,  1.2 , 23.94,  6.84,  5.04],\n",
       "       [ 5.7 ,  4.2 ,  1.3 , 23.94,  7.41,  5.46],\n",
       "       [ 6.2 ,  4.3 ,  1.3 , 26.66,  8.06,  5.59],\n",
       "       [ 5.1 ,  3.  ,  1.1 , 15.3 ,  5.61,  3.3 ],\n",
       "       [ 5.7 ,  4.1 ,  1.3 , 23.37,  7.41,  5.33],\n",
       "       [ 6.3 ,  6.  ,  2.5 , 37.8 , 15.75, 15.  ],\n",
       "       [ 5.8 ,  5.1 ,  1.9 , 29.58, 11.02,  9.69],\n",
       "       [ 7.1 ,  5.9 ,  2.1 , 41.89, 14.91, 12.39],\n",
       "       [ 6.3 ,  5.6 ,  1.8 , 35.28, 11.34, 10.08],\n",
       "       [ 6.5 ,  5.8 ,  2.2 , 37.7 , 14.3 , 12.76],\n",
       "       [ 7.6 ,  6.6 ,  2.1 , 50.16, 15.96, 13.86],\n",
       "       [ 4.9 ,  4.5 ,  1.7 , 22.05,  8.33,  7.65],\n",
       "       [ 7.3 ,  6.3 ,  1.8 , 45.99, 13.14, 11.34],\n",
       "       [ 6.7 ,  5.8 ,  1.8 , 38.86, 12.06, 10.44],\n",
       "       [ 7.2 ,  6.1 ,  2.5 , 43.92, 18.  , 15.25],\n",
       "       [ 6.5 ,  5.1 ,  2.  , 33.15, 13.  , 10.2 ],\n",
       "       [ 6.4 ,  5.3 ,  1.9 , 33.92, 12.16, 10.07],\n",
       "       [ 6.8 ,  5.5 ,  2.1 , 37.4 , 14.28, 11.55],\n",
       "       [ 5.7 ,  5.  ,  2.  , 28.5 , 11.4 , 10.  ],\n",
       "       [ 5.8 ,  5.1 ,  2.4 , 29.58, 13.92, 12.24],\n",
       "       [ 6.4 ,  5.3 ,  2.3 , 33.92, 14.72, 12.19],\n",
       "       [ 6.5 ,  5.5 ,  1.8 , 35.75, 11.7 ,  9.9 ],\n",
       "       [ 7.7 ,  6.7 ,  2.2 , 51.59, 16.94, 14.74],\n",
       "       [ 7.7 ,  6.9 ,  2.3 , 53.13, 17.71, 15.87],\n",
       "       [ 6.  ,  5.  ,  1.5 , 30.  ,  9.  ,  7.5 ],\n",
       "       [ 6.9 ,  5.7 ,  2.3 , 39.33, 15.87, 13.11],\n",
       "       [ 5.6 ,  4.9 ,  2.  , 27.44, 11.2 ,  9.8 ],\n",
       "       [ 7.7 ,  6.7 ,  2.  , 51.59, 15.4 , 13.4 ],\n",
       "       [ 6.3 ,  4.9 ,  1.8 , 30.87, 11.34,  8.82],\n",
       "       [ 6.7 ,  5.7 ,  2.1 , 38.19, 14.07, 11.97],\n",
       "       [ 7.2 ,  6.  ,  1.8 , 43.2 , 12.96, 10.8 ],\n",
       "       [ 6.2 ,  4.8 ,  1.8 , 29.76, 11.16,  8.64],\n",
       "       [ 6.1 ,  4.9 ,  1.8 , 29.89, 10.98,  8.82],\n",
       "       [ 6.4 ,  5.6 ,  2.1 , 35.84, 13.44, 11.76],\n",
       "       [ 7.2 ,  5.8 ,  1.6 , 41.76, 11.52,  9.28],\n",
       "       [ 7.4 ,  6.1 ,  1.9 , 45.14, 14.06, 11.59],\n",
       "       [ 7.9 ,  6.4 ,  2.  , 50.56, 15.8 , 12.8 ],\n",
       "       [ 6.4 ,  5.6 ,  2.2 , 35.84, 14.08, 12.32],\n",
       "       [ 6.3 ,  5.1 ,  1.5 , 32.13,  9.45,  7.65],\n",
       "       [ 6.1 ,  5.6 ,  1.4 , 34.16,  8.54,  7.84],\n",
       "       [ 7.7 ,  6.1 ,  2.3 , 46.97, 17.71, 14.03],\n",
       "       [ 6.3 ,  5.6 ,  2.4 , 35.28, 15.12, 13.44],\n",
       "       [ 6.4 ,  5.5 ,  1.8 , 35.2 , 11.52,  9.9 ],\n",
       "       [ 6.  ,  4.8 ,  1.8 , 28.8 , 10.8 ,  8.64],\n",
       "       [ 6.9 ,  5.4 ,  2.1 , 37.26, 14.49, 11.34],\n",
       "       [ 6.7 ,  5.6 ,  2.4 , 37.52, 16.08, 13.44],\n",
       "       [ 6.9 ,  5.1 ,  2.3 , 35.19, 15.87, 11.73],\n",
       "       [ 5.8 ,  5.1 ,  1.9 , 29.58, 11.02,  9.69],\n",
       "       [ 6.8 ,  5.9 ,  2.3 , 40.12, 15.64, 13.57],\n",
       "       [ 6.7 ,  5.7 ,  2.5 , 38.19, 16.75, 14.25],\n",
       "       [ 6.7 ,  5.2 ,  2.3 , 34.84, 15.41, 11.96],\n",
       "       [ 6.3 ,  5.  ,  1.9 , 31.5 , 11.97,  9.5 ],\n",
       "       [ 6.5 ,  5.2 ,  2.  , 33.8 , 13.  , 10.4 ],\n",
       "       [ 6.2 ,  5.4 ,  2.3 , 33.48, 14.26, 12.42],\n",
       "       [ 5.9 ,  5.1 ,  1.8 , 30.09, 10.62,  9.18]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature expansion\n",
    "poly = PolynomialFeatures(interaction_only=True,include_bias = False)\n",
    "x=poly.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4 , 7.14, 1.02, 0.28],\n",
       "       [1.4 , 6.86, 0.98, 0.28],\n",
       "       [1.3 , 6.11, 0.94, 0.26],\n",
       "       [1.5 , 6.9 , 0.92, 0.3 ],\n",
       "       [1.4 , 7.  , 1.  , 0.28]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature selection\n",
    "x_new = SelectKBest(chi2, k=4).fit_transform(x, y)\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x_new, y, random_state=0)\n",
    "x_new[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after feature expansion and selection\n",
      "\n",
      " Logistic Regression \n",
      "\n",
      "Best parameters: {'C': 10, 'penalty': 'l1'}\n",
      "Best cross-validation score: 0.9732142857142857\n",
      "The accuracy score is: 0.9736842105263158\n",
      "None\n",
      "\n",
      " Random Forest \n",
      "\n",
      "Best parameters: {'max_depth': 2, 'n_estimators': 3}\n",
      "Best cross-validation score: 0.9553571428571429\n",
      "The accuracy score is: 0.9736842105263158\n",
      "None\n",
      "\n",
      " Decision Tree \n",
      "\n",
      "Best parameters: {'max_depth': 4}\n",
      "Best cross-validation score: 0.9642857142857143\n",
      "The accuracy score is: 0.9736842105263158\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"after feature expansion and selection\")\n",
    "\n",
    "def tuningPara_crossValid1(model, param_grid):\n",
    "    kfold = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kfold)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "    accuracy = grid_search.score(x_test, y_test)\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    print('Best cross-validation score:', grid_search.best_score_)\n",
    "    print('The accuracy score is:', accuracy)\n",
    "\n",
    "# Logistic Regression: parameter tuning & cross validation\n",
    "# tunning parameters\n",
    "param_grid = {'penalty':['l1', 'l2'], \n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "print('\\n Logistic Regression \\n')\n",
    "print(tuningPara_crossValid1(LogisticRegression(), param_grid))\n",
    "\n",
    "# Random Forest: parameter tuning & cross validation\n",
    "# tunning parameters \n",
    "# max_feature for classification problem is sqrt(n_features)\n",
    "param_grid = {'n_estimators': [2, 3, 4, 5],\n",
    "              'max_depth':[2, 3, 4, 5]}\n",
    "print('\\n Random Forest \\n')\n",
    "print(tuningPara_crossValid1(RandomForestClassifier(max_features=2, n_jobs=-1), param_grid))\n",
    "\n",
    "# Decision Tree: parameter tuning & cross validation\n",
    "param_grid = {'max_depth':[1, 2, 3, 4, 5]}\n",
    "\n",
    "print('\\n Decision Tree \\n')\n",
    "print(tuningPara_crossValid1(DecisionTreeClassifier(), param_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Iris dataset, the best accuracy is after the combination of feature selection and expansion, and the accuracy score of LogisticRegression is the same as that of Random Forest and Decision Tree (0.9736842105263158). \n",
    "However, the best cross-validation score is LogisticRegression(0.9821428571428571) after feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Results of Feature selection\n",
    "Feature selection can improve the performance of LogisticRegression. However, as for DecisionTree, tuning parameter can have a good performance enough even without feature selection. As for RandomForest, each features may have great impact on the target variables, so after selection, the accuracy is lower than that before selection. \n",
    "\n",
    "### From Results of Feature expansion\n",
    "After feature expansion, the performance of LogisticRegression is improved. However, as for DecisionTree, the result contains the same. And as for RandomForest, the accuracy is instead declined. Feature expansion increases model complexity, which results in the data noise and overfitting problem. It may not suit for RandomForest, so the performance of RandomForest is not as good as before.\n",
    "\n",
    "### Combine feature expansion and selection\n",
    "After the combination of feature selection and expention the cross-validation accuracy has decreased in tree models but increases in LogisticRession model. The decrease may be attributed to the relativly large number of features, which is not suitable for complex tree models but better when fitting simpler models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Congressional Voting Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function of tuning parameters and cross validation \n",
    "def tuningPara_crossValid(model, param_grid, X_train, X_test, y_train, y_test):\n",
    "    kfold = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=kfold)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    accuracy = grid_search.score(X_test, y_test)\n",
    "    model_after_tune = grid_search.best_estimator_\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "    print('Best cross-validation score:', grid_search.best_score_)\n",
    "    print('The accuracy score is:', accuracy)\n",
    "    return model_after_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'house-votes-84.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a578b07f1c19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvoting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'house-votes-84.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvoting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'republican'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'house-votes-84.csv' does not exist"
     ]
    }
   ],
   "source": [
    "voting = pd.read_csv('house-votes-84.csv', header=None)\n",
    "voting.replace('n',0, inplace=True)\n",
    "voting.replace('y',1, inplace=True)\n",
    "voting.replace('?', 2,inplace=True)\n",
    "voting.replace('republican', 0, inplace=True)\n",
    "voting.replace('democrat', 1, inplace=True)\n",
    "X_df= voting.iloc[:, range(1,17)]\n",
    "y_df = voting.iloc[:, 0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, random_state=0)\n",
    "voting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression: parameter tuning & cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty':['l1', 'l2'], \n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "print('Before feature selection:')\n",
    "LogRegModel = tuningPara_crossValid(LogisticRegression(), param_grid, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model-Based Feature Selection (then fit model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nAfter feature selection:')\n",
    "model = SelectFromModel(LogisticRegression(), threshold='median')\n",
    "model.fit(X_train, y_train)\n",
    "X_train_l1 = model.transform(X_train)\n",
    "X_test_l1 = model.transform(X_test)\n",
    "print('Shape of X_train:', X_train_l1.shape)\n",
    "LogRegModel = tuningPara_crossValid(LogisticRegression(), param_grid, X_train_l1, X_test_l1, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest: parameter tuning & cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before feature selection:')\n",
    "param_grid = {'n_estimators': [2, 3, 4, 5],\n",
    "              'max_depth':[2, 3, 4, 5]}\n",
    "RanForModel = tuningPara_crossValid(RandomForestClassifier(max_features=4, n_jobs=-1), param_grid, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection: Univariate Statistics (50% percentile) (then fit model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "select = SelectPercentile(percentile=50) \n",
    "select.fit(X_train, y_train)\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test) \n",
    "print(\"X_train_selected.shape: {}\".format(X_train_selected.shape))\n",
    "print(\"feature selected result:\",select.get_support())\n",
    "\n",
    "print('after feature selection:')\n",
    "param_grid = {'n_estimators': [2, 3, 4, 5],\n",
    "              'max_depth':[2, 3, 4, 5]}\n",
    "RanForModel = tuningPara_crossValid(RandomForestClassifier(max_features=4, n_jobs=-1), param_grid, X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Tree: parameter tuning & cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[1, 2, 3, 4, 5]}\n",
    "clf = DecisionTreeClassifier()\n",
    "print('before feature selection:')\n",
    "DecTreeModel = tuningPara_crossValid(clf, param_grid, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection: Iterative Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "print('After feature selection:')\n",
    "select = RFE(clf, n_features_to_select=8)\n",
    "select.fit(X_train, y_train)\n",
    "X_train_selected = select.transform(X_train)\n",
    "X_test_selected = select.transform(X_test)\n",
    "print(\"X_train_selected.shape: {}\".format(X_train_selected.shape))\n",
    "print(\"feature selected result:\",select.get_support())\n",
    "DecTreeModel = tuningPara_crossValid(clf, param_grid, X_train_selected, X_test_selected, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Expantion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairwise interactions\n",
    "poly = PolynomialFeatures(interaction_only=True,include_bias = False)\n",
    "X_exp_inter=poly.fit_transform(X_df)\n",
    "print('Train dataset size after pairwise interactions(interaction_only):', X_exp_inter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature expansion, interaction_only=False\n",
    "poly=PolynomialFeatures(interaction_only=False, include_bias = False)\n",
    "X_exp_inter_false=poly.fit_transform(X_df)\n",
    "print('Train dataset size after pairwise interactions(interaction_only=False):', X_exp_inter_false.shape)\n",
    "X_exp=poly.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of feature is too large than before which is not good for prediction because the number of datasets is not very large. Thus, we want to do feature selection combine with feature selection.\n",
    "\n",
    "## Combine feature selection (excluding petal-width) and feature expansion together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_chi(n_features, X, y):\n",
    "    select_chi = SelectKBest(chi2, k=n_features)\n",
    "    X_chi_sele = select_chi.fit_transform(X, y)\n",
    "    print(select_chi.get_support())\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_chi_sele, y, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "## feature selection from features after doing feature expantion\n",
    "X_train1, X_test1, y_train1, y_test1 = feature_selection_chi(25, X_exp_inter, y_df)\n",
    "X_train2, X_test2, y_train2, y_test2 = feature_selection_chi(25, X_exp_inter_false, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit models, do cross-validation and calculate accuracy scores after feature engineering\n",
    "print('Logistic regression model:')\n",
    "param_grid = {'penalty':['l1', 'l2'], \n",
    "              'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "print('\\nThe result of interaction_only:')\n",
    "LogRegModel = tuningPara_crossValid(LogisticRegression(), param_grid, X_train1, X_test1, y_train1, y_test1)\n",
    "print('\\nThe result of interaction_only=false:')\n",
    "LogRegModel = tuningPara_crossValid(LogisticRegression(), param_grid, X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest model :')\n",
    "param_grid = {'n_estimators': [2, 3, 4, 5],\n",
    "              'max_depth':[2, 3, 4, 5]}\n",
    "print('\\nThe result of interaction_only:')\n",
    "RanForModel = tuningPara_crossValid(RandomForestClassifier(max_features=4, n_jobs=-1), param_grid, X_train1, X_test1, y_train1, y_test1)\n",
    "print('\\nThe result of interaction_only=false:')\n",
    "RanForModel = tuningPara_crossValid(RandomForestClassifier(max_features=4, n_jobs=-1), param_grid, X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[1, 2, 3, 4, 5]}\n",
    "clf = DecisionTreeClassifier()\n",
    "print('before feature selection:')\n",
    "print('\\nThe result of interaction_only:')\n",
    "DecTreeModel = tuningPara_crossValid(clf, param_grid, X_train1, X_test1, y_train1, y_test1)\n",
    "print('\\nThe result of interaction_only=false:')\n",
    "DecTreeModel = tuningPara_crossValid(clf, param_grid, X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oberservation\n",
    "\n",
    "For Congressional Voting dataset, the best accuracy is given by LogisticRegression (0.9724770642201835) with the combination of feature selection and expantion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Results of Feature selection\n",
    "Feature selection can improve the performance of LogisticRegression. However, as for RandomForest and DecisionTree, tuning parameter can have a good performance enough even without feature selection.\n",
    "\n",
    "### From Results of Feature expantion\n",
    "The number of feature is too large than before which is not good for prediction because the number of datasets is not very large. Thus, we want to do feature selection combine with feature selection.\n",
    "\n",
    "### Combine feature expention and selection\n",
    "After the combination of feature selection and expention the accuracy has decreased in tree models but increase in LogisticRession model. The decrease may be attributed to the relativly large number of features, which is not suitable for complex tree models but better when fitting simpler models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
